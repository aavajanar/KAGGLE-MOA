{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-06T13:33:55.546654Z",
     "iopub.status.busy": "2020-12-06T13:33:55.545761Z",
     "iopub.status.idle": "2020-12-06T13:33:56.671690Z",
     "shell.execute_reply": "2020-12-06T13:33:56.670884Z"
    },
    "papermill": {
     "duration": 1.146577,
     "end_time": "2020-12-06T13:33:56.671824",
     "exception": false,
     "start_time": "2020-12-06T13:33:55.525247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/test_features.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01203,
     "end_time": "2020-12-06T13:33:56.695124",
     "exception": false,
     "start_time": "2020-12-06T13:33:56.683094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Used notebooks:<br>\n",
    "https://www.kaggle.com/nroman/moa-lightgbm-206-models<br>\n",
    "https://www.kaggle.com/pavelvpster/moa-lgb-optuna<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009964,
     "end_time": "2020-12-06T13:33:56.715517",
     "exception": false,
     "start_time": "2020-12-06T13:33:56.705553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-06T13:33:56.747181Z",
     "iopub.status.busy": "2020-12-06T13:33:56.746378Z",
     "iopub.status.idle": "2020-12-06T13:34:05.252142Z",
     "shell.execute_reply": "2020-12-06T13:34:05.251447Z"
    },
    "papermill": {
     "duration": 8.52637,
     "end_time": "2020-12-06T13:34:05.252278",
     "exception": false,
     "start_time": "2020-12-06T13:33:56.725908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/kaggle/input/lish-moa/\"\n",
    "train_features = pd.read_csv(path+\"train_features.csv\")\n",
    "test_features = pd.read_csv(path+\"test_features.csv\")\n",
    "train_targets_scored = pd.read_csv(path+\"train_targets_scored.csv\")\n",
    "\n",
    "# From https://www.kaggle.com/carlmcbrideellis/moa-setting-ctl-vehicle-0-improves-score\n",
    "train_features.at[train_features['cp_type'].str.contains('ctl_vehicle'),train_features.filter(regex='-.*').columns] = 0.0\n",
    "test_features.at[test_features['cp_type'].str.contains('ctl_vehicle'),test_features.filter(regex='-.*').columns] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010251,
     "end_time": "2020-12-06T13:34:05.273228",
     "exception": false,
     "start_time": "2020-12-06T13:34:05.262977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:34:05.300704Z",
     "iopub.status.busy": "2020-12-06T13:34:05.299895Z",
     "iopub.status.idle": "2020-12-06T13:34:05.303479Z",
     "shell.execute_reply": "2020-12-06T13:34:05.302677Z"
    },
    "papermill": {
     "duration": 0.019604,
     "end_time": "2020-12-06T13:34:05.303613",
     "exception": false,
     "start_time": "2020-12-06T13:34:05.284009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def onehotencode(data):\n",
    "    data = pd.get_dummies(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:34:05.334896Z",
     "iopub.status.busy": "2020-12-06T13:34:05.334102Z",
     "iopub.status.idle": "2020-12-06T13:34:05.972460Z",
     "shell.execute_reply": "2020-12-06T13:34:05.971794Z"
    },
    "papermill": {
     "duration": 0.658155,
     "end_time": "2020-12-06T13:34:05.972599",
     "exception": false,
     "start_time": "2020-12-06T13:34:05.314444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data\n",
    "X = train_features.copy()\n",
    "y_train = train_targets_scored.copy()\n",
    "X = X.drop(\"sig_id\", axis=1)\n",
    "y_train = y_train.drop(\"sig_id\", axis=1)\n",
    "\n",
    "X = onehotencode(X)\n",
    "\n",
    "X_test = test_features.copy()\n",
    "sig_id = X_test[\"sig_id\"]\n",
    "X_test = X_test.drop(\"sig_id\", axis=1)\n",
    "X_test = onehotencode(X_test)\n",
    "\n",
    "columns = X_test.columns\n",
    "sub = pd.read_csv(path+\"sample_submission.csv\")\n",
    "\n",
    "X = X.copy()\n",
    "y_train = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010684,
     "end_time": "2020-12-06T13:34:05.995011",
     "exception": false,
     "start_time": "2020-12-06T13:34:05.984327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:34:06.036225Z",
     "iopub.status.busy": "2020-12-06T13:34:06.035426Z",
     "iopub.status.idle": "2020-12-06T14:49:45.992174Z",
     "shell.execute_reply": "2020-12-06T14:49:45.992982Z"
    },
    "papermill": {
     "duration": 4539.987153,
     "end_time": "2020-12-06T14:49:45.993263",
     "exception": false,
     "start_time": "2020-12-06T13:34:06.006110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 1, loss: 0.005500134934250741\n",
      "num: 2, loss: 0.006127405857487018\n",
      "num: 3, loss: 0.007958126867749563\n",
      "num: 4, loss: 0.04568846247628025\n",
      "num: 5, loss: 0.06682891170129239\n",
      "num: 6, loss: 0.020697632301132855\n",
      "num: 7, loss: 0.01587163125010799\n",
      "num: 8, loss: 0.02596268290381516\n",
      "num: 9, loss: 0.0033754323265396415\n",
      "num: 10, loss: 0.05852526625181986\n",
      "num: 11, loss: 0.07681585052995592\n",
      "num: 12, loss: 0.014610311026591525\n",
      "num: 13, loss: 0.0020186398188088354\n",
      "num: 14, loss: 0.011400896074435753\n",
      "num: 15, loss: 0.004318534089361443\n",
      "num: 16, loss: 0.004273171671320986\n",
      "num: 17, loss: 0.014515755752692844\n",
      "num: 18, loss: 0.024580478736376768\n",
      "num: 19, loss: 0.022421103393187647\n",
      "num: 20, loss: 0.011312791607561087\n",
      "num: 21, loss: 0.011566051499098586\n",
      "num: 22, loss: 0.020205856465480315\n",
      "num: 23, loss: 0.0023393104996041717\n",
      "num: 24, loss: 0.012675414367280667\n",
      "num: 25, loss: 0.004298916916073611\n",
      "num: 26, loss: 0.004507812422094568\n",
      "num: 27, loss: 0.004304433207179347\n",
      "num: 28, loss: 0.00618326038239716\n",
      "num: 29, loss: 0.02068094948159834\n",
      "num: 30, loss: 0.011287097507942906\n",
      "num: 31, loss: 0.007660872209743239\n",
      "num: 32, loss: 0.014519206614680995\n",
      "num: 33, loss: 0.014236441580429079\n",
      "num: 34, loss: 0.002170542457757893\n",
      "num: 35, loss: 0.0014679625402995134\n",
      "num: 36, loss: 0.001938778979233022\n",
      "num: 37, loss: 0.022156609685477807\n",
      "num: 38, loss: 0.00446166048681215\n",
      "num: 39, loss: 0.014717997878575065\n",
      "num: 40, loss: 0.0023286703076319964\n",
      "num: 41, loss: 0.017379362386140965\n",
      "num: 42, loss: 0.02222789341008522\n",
      "num: 43, loss: 0.011128707718185195\n",
      "num: 44, loss: 0.046334192408036906\n",
      "num: 45, loss: 0.024469850060607985\n",
      "num: 46, loss: 0.03005501205810407\n",
      "num: 47, loss: 0.001777695358782781\n",
      "num: 48, loss: 0.008969430014248807\n",
      "num: 49, loss: 0.010053055588266576\n",
      "num: 50, loss: 0.019253479572808825\n",
      "num: 51, loss: 0.007953711532210169\n",
      "num: 52, loss: 0.01420106490767023\n",
      "num: 53, loss: 0.009259812650987586\n",
      "num: 54, loss: 0.0022453937467498742\n",
      "num: 55, loss: 0.06321448961407604\n",
      "num: 56, loss: 0.01286569717229294\n",
      "num: 57, loss: 0.016153119624523173\n",
      "num: 58, loss: 0.011308250942169994\n",
      "num: 59, loss: 0.01120572478413947\n",
      "num: 60, loss: 0.006140799566804224\n",
      "num: 61, loss: 0.004329661592563429\n",
      "num: 62, loss: 0.027358910677937463\n",
      "num: 63, loss: 0.006188690237652118\n",
      "num: 64, loss: 0.020800687480811493\n",
      "num: 65, loss: 0.015970218079228046\n",
      "num: 66, loss: 0.003926941394955523\n",
      "num: 67, loss: 0.012853674149144791\n",
      "num: 68, loss: 0.014491531504925626\n",
      "num: 69, loss: 0.015995081422476277\n",
      "num: 70, loss: 0.002339007048523483\n",
      "num: 71, loss: 0.008396420501838055\n",
      "num: 72, loss: 0.08844431647867083\n",
      "num: 73, loss: 0.02767619324495794\n",
      "num: 74, loss: 0.009365525372812367\n",
      "num: 75, loss: 0.008120764438832608\n",
      "num: 76, loss: 0.0022783229323257046\n",
      "num: 77, loss: 0.0142207832998538\n",
      "num: 78, loss: 0.08006532471734118\n",
      "num: 79, loss: 0.03166948842357403\n",
      "num: 80, loss: 0.08517523895082162\n",
      "num: 81, loss: 0.02600434242591111\n",
      "num: 82, loss: 0.002319949336418591\n",
      "num: 83, loss: 0.0014682463778047743\n",
      "num: 84, loss: 0.03936830037593858\n",
      "num: 85, loss: 0.014471839133923475\n",
      "num: 86, loss: 0.010838642019041724\n",
      "num: 87, loss: 0.0050267292848518086\n",
      "num: 88, loss: 0.008167923285600545\n",
      "num: 89, loss: 0.01173262377762285\n",
      "num: 90, loss: 0.02811234920165284\n",
      "num: 91, loss: 0.00399130522806141\n",
      "num: 92, loss: 0.006171022765867938\n",
      "num: 93, loss: 0.007414620306809222\n",
      "num: 94, loss: 0.02843532718404709\n",
      "num: 95, loss: 0.040863989403151245\n",
      "num: 96, loss: 0.01235400797167253\n",
      "num: 97, loss: 0.013966292440130056\n",
      "num: 98, loss: 0.0046019378095248165\n",
      "num: 99, loss: 0.020937914417429766\n",
      "num: 100, loss: 0.07824468093807817\n",
      "num: 101, loss: 0.00615804023546213\n",
      "num: 102, loss: 0.012161980183584435\n",
      "num: 103, loss: 0.02049040666678797\n",
      "num: 104, loss: 0.012434121125749594\n",
      "num: 105, loss: 0.017287882667177002\n",
      "num: 106, loss: 0.055571422644478945\n",
      "num: 107, loss: 0.006504011608940231\n",
      "num: 108, loss: 0.009891523399953563\n",
      "num: 109, loss: 0.020376687302779257\n",
      "num: 110, loss: 0.01335520838395056\n",
      "num: 111, loss: 0.007574182137792703\n",
      "num: 112, loss: 0.010105509954396614\n",
      "num: 113, loss: 0.007524571324974449\n",
      "num: 114, loss: 0.009947871475924802\n",
      "num: 115, loss: 0.019023782430443868\n",
      "num: 116, loss: 0.009498096144883238\n",
      "num: 117, loss: 0.013423246753008664\n",
      "num: 118, loss: 0.0129345136290544\n",
      "num: 119, loss: 0.01632209980447687\n",
      "num: 120, loss: 0.020454500444914078\n",
      "num: 121, loss: 0.0023389902345131246\n",
      "num: 122, loss: 0.0023397796524605224\n",
      "num: 123, loss: 0.01804031968287102\n",
      "num: 124, loss: 0.00432931820109276\n",
      "num: 125, loss: 0.017729916998560954\n",
      "num: 126, loss: 0.002239900615240047\n",
      "num: 127, loss: 0.006357050526098052\n",
      "num: 128, loss: 0.009560581576407367\n",
      "num: 129, loss: 0.02051619709082946\n",
      "num: 130, loss: 0.008160018857122893\n",
      "num: 131, loss: 0.004325240278685538\n",
      "num: 132, loss: 0.02350395888020244\n",
      "num: 133, loss: 0.005881306210402263\n",
      "num: 134, loss: 0.017700773334460868\n",
      "num: 135, loss: 0.014322106545387688\n",
      "num: 136, loss: 0.011385507342743937\n",
      "num: 137, loss: 0.032344196642537536\n",
      "num: 138, loss: 0.0023287700311489324\n",
      "num: 139, loss: 0.008432668391126977\n",
      "num: 140, loss: 0.0038824712235491074\n",
      "num: 141, loss: 0.008520798893116762\n",
      "num: 142, loss: 0.002664097377573531\n",
      "num: 143, loss: 0.0046130885503352925\n",
      "num: 144, loss: 0.017750123829691364\n",
      "num: 145, loss: 0.026011000877508\n",
      "num: 146, loss: 0.01156649048915417\n",
      "num: 147, loss: 0.01195098795820982\n",
      "num: 148, loss: 0.007893420004236531\n",
      "num: 149, loss: 0.017155840541635742\n",
      "num: 150, loss: 0.023216377023211516\n",
      "num: 151, loss: 0.006174100680885045\n",
      "num: 152, loss: 0.05940932555542817\n",
      "num: 153, loss: 0.00816853022284498\n",
      "num: 154, loss: 0.028383461316999717\n",
      "num: 155, loss: 0.009822969861324844\n",
      "num: 156, loss: 0.016132030563993496\n",
      "num: 157, loss: 0.026392423767608114\n",
      "num: 158, loss: 0.02583256868011393\n",
      "num: 159, loss: 0.00962996395703219\n",
      "num: 160, loss: 0.030176825717963915\n",
      "num: 161, loss: 0.006063132777411778\n",
      "num: 162, loss: 0.011274092559654433\n",
      "num: 163, loss: 0.02328356118931961\n",
      "num: 164, loss: 0.001370247297297462\n",
      "num: 165, loss: 0.014317228601393122\n",
      "num: 166, loss: 0.002220549873643512\n",
      "num: 167, loss: 0.023654083457139197\n",
      "num: 168, loss: 0.006461382457314039\n",
      "num: 169, loss: 0.016467409352089124\n",
      "num: 170, loss: 0.008546597961880637\n",
      "num: 171, loss: 0.004330348919840764\n",
      "num: 172, loss: 0.013328453017776198\n",
      "num: 173, loss: 0.0023338157777038535\n",
      "num: 174, loss: 0.009890855533632767\n",
      "num: 175, loss: 0.008816851156752773\n",
      "num: 176, loss: 0.008017655104512142\n",
      "num: 177, loss: 0.05513227281703614\n",
      "num: 178, loss: 0.08312955532240077\n",
      "num: 179, loss: 0.013404013317607821\n",
      "num: 180, loss: 0.011302186855545533\n",
      "num: 181, loss: 0.011282294239778121\n",
      "num: 182, loss: 0.00811991108496836\n",
      "num: 183, loss: 0.060896852762255496\n",
      "num: 184, loss: 0.008174630972073637\n",
      "num: 185, loss: 0.016907579547047875\n",
      "num: 186, loss: 0.002327832447615299\n",
      "num: 187, loss: 0.005739304517113989\n",
      "num: 188, loss: 0.01730352845640982\n",
      "num: 189, loss: 0.0029201642612284888\n",
      "num: 190, loss: 0.006439839437408689\n",
      "num: 191, loss: 0.01087007385034002\n",
      "num: 192, loss: 0.009610733513738617\n",
      "num: 193, loss: 0.0026724040523962863\n",
      "num: 194, loss: 0.011038538288472129\n",
      "num: 195, loss: 0.016255418370837025\n",
      "num: 196, loss: 0.006174537211660275\n",
      "num: 197, loss: 0.0023382571755202106\n",
      "num: 198, loss: 0.007613174282848091\n",
      "num: 199, loss: 0.014517303494241487\n",
      "num: 200, loss: 0.02421454367903548\n",
      "num: 201, loss: 0.020448162853864447\n",
      "num: 202, loss: 0.0023351852862858453\n",
      "num: 203, loss: 0.027588557829904752\n",
      "num: 204, loss: 0.008488186651146463\n",
      "num: 205, loss: 0.007776986908085914\n",
      "num: 206, loss: 0.009652758441572755\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': \"gbdt\",\n",
    "    'num_leaves': 500,\n",
    "    'min_child_weight': 0.01,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.6,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'bagging_seed': 11,\n",
    "    'verbosity': 0,\n",
    "    'reg_alpha': 0.4,\n",
    "    'reg_lambda': 0.6,\n",
    "    'random_state': 0\n",
    "         }\n",
    "\n",
    "accumulative_loss = 0\n",
    "skf = StratifiedKFold(n_splits=3, random_state=0, shuffle=True)\n",
    "\n",
    "# 206 different models. One for each label\n",
    "for model, target in enumerate(y_train, 1):\n",
    "    y = y_train[target]\n",
    "    preds = np.zeros(X_test.shape[0])\n",
    "    oof = np.zeros(X.shape[0])\n",
    "\n",
    "    for trn_idx, test_idx in skf.split(X, y):\n",
    "        \n",
    "        trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X.iloc[test_idx], label=y.iloc[test_idx])\n",
    "        clf = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds=20)\n",
    "        oof[test_idx] = clf.predict(X.iloc[test_idx])\n",
    "        preds += clf.predict(X_test) / skf.n_splits\n",
    "\n",
    "    sub[target] = preds\n",
    "    loss = log_loss(y, oof)\n",
    "    accumulative_loss += loss\n",
    "    print(f\"num: {model}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T14:49:46.229628Z",
     "iopub.status.busy": "2020-12-06T14:49:46.228712Z",
     "iopub.status.idle": "2020-12-06T14:49:46.234002Z",
     "shell.execute_reply": "2020-12-06T14:49:46.232997Z"
    },
    "papermill": {
     "duration": 0.115141,
     "end_time": "2020-12-06T14:49:46.234175",
     "exception": false,
     "start_time": "2020-12-06T14:49:46.119034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall loss: 0.01617\n"
     ]
    }
   ],
   "source": [
    "print('Overall loss: {:.5f}'.format(accumulative_loss / 206))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T14:49:46.431860Z",
     "iopub.status.busy": "2020-12-06T14:49:46.430892Z",
     "iopub.status.idle": "2020-12-06T14:49:49.120718Z",
     "shell.execute_reply": "2020-12-06T14:49:49.119833Z"
    },
    "papermill": {
     "duration": 2.789997,
     "end_time": "2020-12-06T14:49:49.120855",
     "exception": false,
     "start_time": "2020-12-06T14:49:46.330858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 4558.992485,
   "end_time": "2020-12-06T14:49:49.424490",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-06T13:33:50.432005",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
